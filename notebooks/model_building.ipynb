{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "69297240",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from  sklearn.ensemble import IsolationForest\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.preprocessing  import LabelEncoder\n",
        "from sklearn import linear_model \n",
        "from sklearn import tree \n",
        "from sklearn import ensemble \n",
        "from sklearn import metrics \n",
        "from sklearn import preprocessing \n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from scipy.stats import zscore"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1556721b",
      "metadata": {},
      "source": [
        "Подготовалтиваем данные для моделей"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "3f5031fc",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_balances=pd.read_csv('../data/processed/bank_fin_processed.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "7999eaab",
      "metadata": {},
      "outputs": [],
      "source": [
        "X = df_balances.drop(['deposit'], axis=1)\n",
        "y = df_balances['deposit']\n",
        " \n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state = 42, test_size = 0.33)\n",
        "select_best_estimator = SelectKBest(score_func=f_classif, k=15).fit(X_train, y_train)\n",
        "X_train = pd.DataFrame(select_best_estimator.transform(X_train), columns = list(select_best_estimator.get_feature_names_out()))\n",
        "X_test = pd.DataFrame(select_best_estimator.transform(X_test), columns = list(select_best_estimator.get_feature_names_out()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "563c1a5c",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Нормализация\n",
        "scaler = MinMaxScaler().fit(X_train)\n",
        "X_train = pd.DataFrame(scaler.transform(X_train), columns=X_train.columns)\n",
        "X_test = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "4a5207f1",
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_model(clf, X_test, y_test):\n",
        "    print(\"accuracy: \", metrics.accuracy_score(y_test, clf.predict(X_test)))\n",
        "    print(\"f1 score: \", metrics.f1_score(y_test, clf.predict(X_test)))\n",
        "    print(\"precision: \", metrics.precision_score(y_test, clf.predict(X_test)))\n",
        "    print(\"recall: \", metrics.recall_score(y_test, clf.predict(X_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "be4527ab",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy:  0.8031430934656741\n",
            "f1 score:  0.7811158798283262\n",
            "precision:  0.8229974160206718\n",
            "recall:  0.7432905484247374\n"
          ]
        }
      ],
      "source": [
        "# обучаем логистическую регрессию и рассчитайте метрики качества\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "clf = LogisticRegression(solver=\"sag\", random_state=42).fit(X_train, y_train)\n",
        "test_model(clf, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "63c649a0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train accuracy:  0.9997283346916599\n",
            "test metrics: \n",
            "accuracy:  0.7515853322304935\n",
            "f1 score:  0.7327202610501334\n",
            "precision:  0.7453228726614364\n",
            "recall:  0.720536756126021\n"
          ]
        }
      ],
      "source": [
        "# обучаем решающие деревья, настраиваем максимальную глубину\n",
        "\n",
        "clf = DecisionTreeClassifier(criterion = 'entropy', random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "print(\"train accuracy: \", metrics.accuracy_score(y_train, clf.predict(X_train)))\n",
        "print(\"test metrics: \")\n",
        "test_model(clf, X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bda68b56",
      "metadata": {},
      "source": [
        "Наблюдаем сильное переобучение.  \n",
        "Подберем наилучшее значение гиперпараметра - глубину дерева"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f7e95fd",
      "metadata": {},
      "source": [
        "for depth in range(2, 10):\n",
        "    clf = DecisionTreeClassifier(max_depth=depth, criterion = 'entropy', random_state=42)\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    print(f\"MX_DEPTH={depth}\")\n",
        "    print(\"train accuracy: \", metrics.accuracy_score(y_train, clf.predict(X_train)))\n",
        "    print(\"test metrics: \")\n",
        "    test_model(clf, X_test, y_test)\n",
        "    print(\"\\n\"*3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "2b23ccc7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# подбераем оптимальные параметры с помощью gridsearch\n",
        "svc = DecisionTreeClassifier()\n",
        "parameters = {'min_samples_split': [2, 5, 7, 10], 'max_depth':[3, 5, 7], \"random_state\": [42]}\n",
        "clf = GridSearchCV(svc, parameters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "7c821e32",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy:  0.8149986214502344\n",
            "f1 score:  0.8116755543081673\n",
            "precision:  0.7820443482963764\n",
            "recall:  0.8436406067677946\n",
            "None\n",
            "Лучшие параметры:  {'max_depth': 7, 'min_samples_split': 2, 'random_state': 42}\n"
          ]
        }
      ],
      "source": [
        "clf.fit(X_train, y_train)\n",
        "print(test_model(clf, X_test, y_test))\n",
        "print(\"Лучшие параметры: \", clf.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e756daab",
      "metadata": {},
      "source": [
        "#### Решение задачи классификации: ансамбли моделей и построение прогноза"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "0bbea2b2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy:  0.8235456299972429\n",
            "f1 score:  0.8159861989649224\n",
            "precision:  0.8044217687074829\n",
            "recall:  0.8278879813302217\n"
          ]
        }
      ],
      "source": [
        "# обучаем на данных случайный лес\n",
        "clf = RandomForestClassifier(n_estimators = 100, criterion = 'gini', min_samples_leaf = 5, max_depth = 10, random_state = 42)\n",
        "clf.fit(X_train, y_train)\n",
        "test_model(clf, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "4fc9f9f4",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy:  0.8249241797628895\n",
            "f1 score:  0.8161019403417318\n",
            "precision:  0.8102357676825762\n",
            "recall:  0.8220536756126021\n"
          ]
        }
      ],
      "source": [
        "# используем для классификации градиентный бустинг и сравниваемЧ качество со случайным лесом\n",
        "# обучаем на  данных случайный лес\n",
        "clf = GradientBoostingClassifier(n_estimators = 300, min_samples_leaf = 5, max_depth = 5, random_state = 42, learning_rate=0.05)\n",
        "clf.fit(X_train, y_train)\n",
        "test_model(clf, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "26ec0ddf",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy:  0.8238213399503722\n",
            "f1 score:  0.8136482939632546\n",
            "precision:  0.8134110787172012\n",
            "recall:  0.8138856476079347\n"
          ]
        }
      ],
      "source": [
        "\n",
        "clf1 = RandomForestClassifier(n_estimators = 100, criterion = 'gini', min_samples_leaf = 5, max_depth = 10, random_state = 42)\n",
        "clf2 = GradientBoostingClassifier(n_estimators = 300, min_samples_leaf = 5, max_depth = 5, random_state = 42, learning_rate=0.05)\n",
        "clf3 = LogisticRegression(solver=\"sag\", random_state=42).fit(X_train, y_train)\n",
        "\n",
        "estimators = [(\"rf\", clf1), (\"gbc\", clf2), (\"lr\", clf3)]\n",
        "main_clf = StackingClassifier(estimators=estimators,\n",
        "                         final_estimator=LogisticRegression())\n",
        "main_clf.fit(X_train, y_train)\n",
        "test_model(main_clf, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "996db191",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "balance             0.070068\n",
            "housing             0.053103\n",
            "loan                0.008972\n",
            "duration            0.510826\n",
            "campaign            0.021073\n",
            "pdays               0.051025\n",
            "previous            0.013983\n",
            "job_student         0.006209\n",
            "contact_unknown     0.080405\n",
            "month_mar           0.035356\n",
            "month_may           0.010407\n",
            "month_oct           0.021709\n",
            "month_sep           0.009282\n",
            "poutcome_success    0.106889\n",
            "poutcome_unknown    0.000694\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# оцениваем, какие признаки демонстрируют наибольшую  важность в модели градиентного бустинга\n",
        "clf = GradientBoostingClassifier(n_estimators = 300, min_samples_leaf = 5, max_depth = 5, random_state = 42, learning_rate=0.05)\n",
        "clf.fit(X_train, y_train)\n",
        "df_balances_feature_imp = pd.Series(clf.feature_importances_, index=X_train.columns.values)\n",
        "print(df_balances_feature_imp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "4e090ce1",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-06-17 16:48:22,628] A new study created in memory with name: no-name-223ba16d-a7a7-4fba-b7ce-e4be61c1d1dd\n",
            "[I 2024-06-17 16:48:23,150] Trial 0 finished with value: 0.8161281098084072 and parameters: {'n_estimators': 143, 'max_depth': 19, 'min_samples_leaf': 6}. Best is trial 0 with value: 0.8161281098084072.\n",
            "[I 2024-06-17 16:48:23,748] Trial 1 finished with value: 0.8157516527737856 and parameters: {'n_estimators': 174, 'max_depth': 25, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.8161281098084072.\n",
            "[I 2024-06-17 16:48:24,203] Trial 2 finished with value: 0.81566161760503 and parameters: {'n_estimators': 118, 'max_depth': 25, 'min_samples_leaf': 5}. Best is trial 0 with value: 0.8161281098084072.\n",
            "[I 2024-06-17 16:48:24,578] Trial 3 finished with value: 0.8121387283236994 and parameters: {'n_estimators': 115, 'max_depth': 11, 'min_samples_leaf': 10}. Best is trial 0 with value: 0.8161281098084072.\n",
            "[I 2024-06-17 16:48:24,984] Trial 4 finished with value: 0.8146651270207852 and parameters: {'n_estimators': 108, 'max_depth': 26, 'min_samples_leaf': 10}. Best is trial 0 with value: 0.8161281098084072.\n",
            "[I 2024-06-17 16:48:25,593] Trial 5 finished with value: 0.8209682039530221 and parameters: {'n_estimators': 157, 'max_depth': 12, 'min_samples_leaf': 3}. Best is trial 5 with value: 0.8209682039530221.\n",
            "[I 2024-06-17 16:48:26,208] Trial 6 finished with value: 0.8195038494439693 and parameters: {'n_estimators': 138, 'max_depth': 19, 'min_samples_leaf': 2}. Best is trial 5 with value: 0.8209682039530221.\n",
            "[I 2024-06-17 16:48:26,843] Trial 7 finished with value: 0.8133640552995391 and parameters: {'n_estimators': 191, 'max_depth': 26, 'min_samples_leaf': 10}. Best is trial 5 with value: 0.8209682039530221.\n",
            "[I 2024-06-17 16:48:27,328] Trial 8 finished with value: 0.82 and parameters: {'n_estimators': 134, 'max_depth': 11, 'min_samples_leaf': 3}. Best is trial 5 with value: 0.8209682039530221.\n",
            "[I 2024-06-17 16:48:28,177] Trial 9 finished with value: 0.8136947218259629 and parameters: {'n_estimators': 177, 'max_depth': 22, 'min_samples_leaf': 2}. Best is trial 5 with value: 0.8209682039530221.\n",
            "[I 2024-06-17 16:48:28,786] Trial 10 finished with value: 0.8175559380378657 and parameters: {'n_estimators': 163, 'max_depth': 13, 'min_samples_leaf': 4}. Best is trial 5 with value: 0.8209682039530221.\n",
            "[I 2024-06-17 16:48:29,313] Trial 11 finished with value: 0.8216833095577746 and parameters: {'n_estimators': 135, 'max_depth': 15, 'min_samples_leaf': 4}. Best is trial 11 with value: 0.8216833095577746.\n",
            "[I 2024-06-17 16:48:29,906] Trial 12 finished with value: 0.8217142857142857 and parameters: {'n_estimators': 158, 'max_depth': 15, 'min_samples_leaf': 4}. Best is trial 12 with value: 0.8217142857142857.\n",
            "[I 2024-06-17 16:48:30,397] Trial 13 finished with value: 0.8179736691471093 and parameters: {'n_estimators': 129, 'max_depth': 16, 'min_samples_leaf': 5}. Best is trial 12 with value: 0.8217142857142857.\n",
            "[I 2024-06-17 16:48:30,935] Trial 14 finished with value: 0.8191458870736601 and parameters: {'n_estimators': 152, 'max_depth': 15, 'min_samples_leaf': 7}. Best is trial 12 with value: 0.8217142857142857.\n",
            "[I 2024-06-17 16:48:31,336] Trial 15 finished with value: 0.8174261966179421 and parameters: {'n_estimators': 100, 'max_depth': 30, 'min_samples_leaf': 4}. Best is trial 12 with value: 0.8217142857142857.\n",
            "[I 2024-06-17 16:48:32,076] Trial 16 finished with value: 0.8177142857142857 and parameters: {'n_estimators': 198, 'max_depth': 16, 'min_samples_leaf': 5}. Best is trial 12 with value: 0.8217142857142857.\n",
            "[I 2024-06-17 16:48:32,668] Trial 17 finished with value: 0.8164084911072863 and parameters: {'n_estimators': 168, 'max_depth': 14, 'min_samples_leaf': 7}. Best is trial 12 with value: 0.8217142857142857.\n",
            "[I 2024-06-17 16:48:33,186] Trial 18 finished with value: 0.8189877037460681 and parameters: {'n_estimators': 128, 'max_depth': 18, 'min_samples_leaf': 4}. Best is trial 12 with value: 0.8217142857142857.\n",
            "[I 2024-06-17 16:48:33,832] Trial 19 finished with value: 0.8174807197943444 and parameters: {'n_estimators': 145, 'max_depth': 22, 'min_samples_leaf': 3}. Best is trial 12 with value: 0.8217142857142857.\n",
            "[I 2024-06-17 16:48:34,326] Trial 20 finished with value: 0.8172661870503597 and parameters: {'n_estimators': 156, 'max_depth': 10, 'min_samples_leaf': 6}. Best is trial 12 with value: 0.8217142857142857.\n",
            "[I 2024-06-17 16:48:34,932] Trial 21 finished with value: 0.8203661327231121 and parameters: {'n_estimators': 158, 'max_depth': 13, 'min_samples_leaf': 3}. Best is trial 12 with value: 0.8217142857142857.\n",
            "[I 2024-06-17 16:48:35,527] Trial 22 finished with value: 0.8205714285714286 and parameters: {'n_estimators': 149, 'max_depth': 17, 'min_samples_leaf': 3}. Best is trial 12 with value: 0.8217142857142857.\n",
            "[I 2024-06-17 16:48:36,118] Trial 23 finished with value: 0.8181296615031555 and parameters: {'n_estimators': 183, 'max_depth': 12, 'min_samples_leaf': 4}. Best is trial 12 with value: 0.8217142857142857.\n",
            "[I 2024-06-17 16:48:36,744] Trial 24 finished with value: 0.822585267985096 and parameters: {'n_estimators': 164, 'max_depth': 14, 'min_samples_leaf': 2}. Best is trial 24 with value: 0.822585267985096.\n",
            "[I 2024-06-17 16:48:37,533] Trial 25 finished with value: 0.8205857264714245 and parameters: {'n_estimators': 167, 'max_depth': 21, 'min_samples_leaf': 2}. Best is trial 24 with value: 0.822585267985096.\n",
            "[I 2024-06-17 16:48:38,044] Trial 26 finished with value: 0.8213166144200627 and parameters: {'n_estimators': 122, 'max_depth': 15, 'min_samples_leaf': 2}. Best is trial 24 with value: 0.822585267985096.\n",
            "[I 2024-06-17 16:48:38,575] Trial 27 finished with value: 0.8167808219178082 and parameters: {'n_estimators': 140, 'max_depth': 17, 'min_samples_leaf': 5}. Best is trial 24 with value: 0.822585267985096.\n",
            "[I 2024-06-17 16:48:39,208] Trial 28 finished with value: 0.8169014084507042 and parameters: {'n_estimators': 182, 'max_depth': 14, 'min_samples_leaf': 6}. Best is trial 24 with value: 0.822585267985096.\n",
            "[I 2024-06-17 16:48:39,776] Trial 29 finished with value: 0.8189335614485315 and parameters: {'n_estimators': 146, 'max_depth': 20, 'min_samples_leaf': 4}. Best is trial 24 with value: 0.822585267985096.\n",
            "[I 2024-06-17 16:48:40,360] Trial 30 finished with value: 0.8148997134670487 and parameters: {'n_estimators': 172, 'max_depth': 19, 'min_samples_leaf': 7}. Best is trial 24 with value: 0.822585267985096.\n",
            "[I 2024-06-17 16:48:40,871] Trial 31 finished with value: 0.8202791227570493 and parameters: {'n_estimators': 126, 'max_depth': 15, 'min_samples_leaf': 2}. Best is trial 24 with value: 0.822585267985096.\n",
            "[I 2024-06-17 16:48:41,326] Trial 32 finished with value: 0.8204104903078677 and parameters: {'n_estimators': 119, 'max_depth': 15, 'min_samples_leaf': 2}. Best is trial 24 with value: 0.822585267985096.\n",
            "[I 2024-06-17 16:48:41,850] Trial 33 finished with value: 0.8212753788961967 and parameters: {'n_estimators': 135, 'max_depth': 17, 'min_samples_leaf': 3}. Best is trial 24 with value: 0.822585267985096.\n",
            "[I 2024-06-17 16:48:42,276] Trial 34 finished with value: 0.8190421565815887 and parameters: {'n_estimators': 122, 'max_depth': 13, 'min_samples_leaf': 6}. Best is trial 24 with value: 0.822585267985096.\n",
            "[I 2024-06-17 16:48:42,717] Trial 35 finished with value: 0.8201315413211324 and parameters: {'n_estimators': 111, 'max_depth': 14, 'min_samples_leaf': 2}. Best is trial 24 with value: 0.822585267985096.\n",
            "[I 2024-06-17 16:48:43,200] Trial 36 finished with value: 0.8178160919540229 and parameters: {'n_estimators': 162, 'max_depth': 10, 'min_samples_leaf': 5}. Best is trial 24 with value: 0.822585267985096.\n",
            "[I 2024-06-17 16:48:43,719] Trial 37 finished with value: 0.8223175965665236 and parameters: {'n_estimators': 153, 'max_depth': 12, 'min_samples_leaf': 3}. Best is trial 24 with value: 0.822585267985096.\n",
            "[I 2024-06-17 16:48:44,220] Trial 38 finished with value: 0.8220823798627003 and parameters: {'n_estimators': 151, 'max_depth': 12, 'min_samples_leaf': 3}. Best is trial 24 with value: 0.822585267985096.\n",
            "[I 2024-06-17 16:48:44,679] Trial 39 finished with value: 0.813920046016681 and parameters: {'n_estimators': 152, 'max_depth': 11, 'min_samples_leaf': 9}. Best is trial 24 with value: 0.822585267985096.\n",
            "[I 2024-06-17 16:48:45,221] Trial 40 finished with value: 0.8219805380652547 and parameters: {'n_estimators': 160, 'max_depth': 12, 'min_samples_leaf': 3}. Best is trial 24 with value: 0.822585267985096.\n",
            "[I 2024-06-17 16:48:45,788] Trial 41 finished with value: 0.821173104434907 and parameters: {'n_estimators': 161, 'max_depth': 12, 'min_samples_leaf': 3}. Best is trial 24 with value: 0.822585267985096.\n",
            "[I 2024-06-17 16:48:46,313] Trial 42 finished with value: 0.8215720022948939 and parameters: {'n_estimators': 168, 'max_depth': 10, 'min_samples_leaf': 3}. Best is trial 24 with value: 0.822585267985096.\n",
            "[I 2024-06-17 16:48:46,878] Trial 43 finished with value: 0.8209682039530221 and parameters: {'n_estimators': 155, 'max_depth': 12, 'min_samples_leaf': 3}. Best is trial 24 with value: 0.822585267985096.\n",
            "[I 2024-06-17 16:48:47,443] Trial 44 finished with value: 0.8221524407650586 and parameters: {'n_estimators': 177, 'max_depth': 11, 'min_samples_leaf': 4}. Best is trial 24 with value: 0.822585267985096.\n",
            "[I 2024-06-17 16:48:48,049] Trial 45 finished with value: 0.8228898426323319 and parameters: {'n_estimators': 176, 'max_depth': 11, 'min_samples_leaf': 2}. Best is trial 45 with value: 0.8228898426323319.\n",
            "[I 2024-06-17 16:48:48,696] Trial 46 finished with value: 0.822419216471261 and parameters: {'n_estimators': 179, 'max_depth': 11, 'min_samples_leaf': 2}. Best is trial 45 with value: 0.8228898426323319.\n",
            "[I 2024-06-17 16:48:49,320] Trial 47 finished with value: 0.8221841052029731 and parameters: {'n_estimators': 177, 'max_depth': 11, 'min_samples_leaf': 2}. Best is trial 45 with value: 0.8228898426323319.\n",
            "[I 2024-06-17 16:48:49,917] Trial 48 finished with value: 0.8184157849585358 and parameters: {'n_estimators': 187, 'max_depth': 10, 'min_samples_leaf': 2}. Best is trial 45 with value: 0.8228898426323319.\n",
            "[I 2024-06-17 16:48:50,601] Trial 49 finished with value: 0.8221841052029731 and parameters: {'n_estimators': 193, 'max_depth': 11, 'min_samples_leaf': 2}. Best is trial 45 with value: 0.8228898426323319.\n"
          ]
        }
      ],
      "source": [
        "# Реализуем оптимизацию гиперпараметров с помощью Optuna\n",
        "\n",
        "import optuna\n",
        "\n",
        "def objective(trial):\n",
        "    n_estimators = trial.suggest_int('n_estimators', 100, 200, 1)\n",
        "    max_depth = trial.suggest_int('max_depth', 10, 30, 1)\n",
        "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 10, 1)\n",
        "\n",
        "    clf = RandomForestClassifier(n_estimators = n_estimators,\n",
        "                                    min_samples_leaf = min_samples_leaf,\n",
        "                                    max_depth = max_depth, random_state = 42, criterion = 'gini')\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    return metrics.f1_score(y_test, clf.predict(X_test))\n",
        "\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "96ed29ca",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy:  0.8293355390129584\n",
            "f1 score:  0.8228898426323319\n",
            "precision:  0.8074115665356542\n",
            "recall:  0.838973162193699\n"
          ]
        }
      ],
      "source": [
        "best_params = study.best_params\n",
        "clf = RandomForestClassifier(random_state = 42, **best_params).fit(X_train, y_train)\n",
        "test_model(clf, X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3fb8841",
      "metadata": {},
      "source": [
        "Результат был улучшен по сравнению с предыдущими  моделями"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3c549c5",
      "metadata": {},
      "source": [
        "### Альтернативный метод оптимизации гиперпараметров\n",
        "#### Применим популярный метод - Hyperopt\n",
        "Hyperopt использует в основном алгоритмы, основанные на процессах оценки, такие как Tree-structured Parzen Estimator (TPE) и случайный поиск.\n",
        "Код для его установки можно запустить в слудующей ячейке"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "93166f84",
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install hyperopt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "1d4e2c12",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100%|██████████| 50/50 [00:25<00:00,  1.94trial/s, best loss: -0.822419216471261]\n",
            "Лучшие параметры:\n",
            "{'max_depth': 1, 'min_samples_leaf': 0, 'n_estimators': 84}\n"
          ]
        }
      ],
      "source": [
        "from hyperopt import hp, fmin, tpe, Trials, STATUS_OK\n",
        "\n",
        "# Определение пространства поиска гиперпараметров\n",
        "space = {\n",
        "    'n_estimators': hp.choice('n_estimators', range(100, 201)),  # границы, как в Optuna\n",
        "    'max_depth': hp.choice('max_depth', range(10, 31)),\n",
        "    'min_samples_leaf': hp.choice('min_samples_leaf', range(2, 11))\n",
        "}\n",
        "\n",
        "# Функция для оптимизации\n",
        "def objective(params):\n",
        "    clf = RandomForestClassifier(**params, random_state=42, criterion='gini')\n",
        "    clf.fit(X_train, y_train)\n",
        "    score = metrics.f1_score(y_test, clf.predict(X_test))\n",
        "    return {'loss': -score, 'status': STATUS_OK, 'params': params}\n",
        "\n",
        "# Запуск оптимизации\n",
        "trials = Trials()\n",
        "best = fmin(fn=objective,\n",
        "            space=space,\n",
        "            algo=tpe.suggest,\n",
        "            max_evals=50,\n",
        "            trials=trials)\n",
        "\n",
        "print(\"Лучшие параметры:\")\n",
        "print(best)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "82e74a59",
      "metadata": {},
      "outputs": [],
      "source": [
        "best = trials.best_trial[\"result\"][\"params\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "c7b4249f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy:  0.8287841191066998\n",
            "f1 score:  0.822419216471261\n",
            "precision:  0.8065058889512058\n",
            "recall:  0.838973162193699\n"
          ]
        }
      ],
      "source": [
        "clf = RandomForestClassifier(random_state = 42, **best).fit(X_train, y_train)\n",
        "test_model(clf, X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6cbc673a",
      "metadata": {},
      "source": [
        "Также в коде выше представлен дополнительный меотд подбора гиперпараметров - Hyperopt\n",
        "В данном случае он показал себя хуже чем популярный метод - Optuna\n",
        "Метрики итоговой модели прииспользовании Optuna:\n",
        "accuracy:  0.8293355390129584\n",
        "f1 score:  0.823193373321908\n",
        "precision:  0.8063794068270845\n",
        "recall:  0.8407234539089848\n",
        "\n",
        "Метрики итоговой модели прииспользовании Hyperopt:\n",
        "accuracy:  0.8287841191066998\n",
        "f1 score:  0.822520720205773\n",
        "precision:  0.8061624649859944\n",
        "recall:  0.8395565927654609\n",
        "\n",
        "Таким образом, немного лучше себя показывает перебор параметров с помощью алгоритма Optuna"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
